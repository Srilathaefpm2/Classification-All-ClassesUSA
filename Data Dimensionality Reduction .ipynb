{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>emp_length_int</th>\n",
       "      <th>home_ownership_cat</th>\n",
       "      <th>income_cat</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>term_cat</th>\n",
       "      <th>purpose_cat</th>\n",
       "      <th>interest_payment_cat</th>\n",
       "      <th>loan_condition</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>grade_cat</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>installment</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  emp_length_int  home_ownership_cat  income_cat  loan_amount  \\\n",
       "0     4               2                   1           1            0   \n",
       "1     4               0                   1           1            0   \n",
       "2     4               2                   1           1            0   \n",
       "3     4               2                   1           1            1   \n",
       "4     4               0                   1           1            0   \n",
       "\n",
       "   term_cat  purpose_cat  interest_payment_cat  loan_condition  interest_rate  \\\n",
       "0         1            1                     1               1              2   \n",
       "1         2            2                     2               0              3   \n",
       "2         1            3                     2               1              3   \n",
       "3         1            4                     2               1              2   \n",
       "4         2            4                     1               1              2   \n",
       "\n",
       "   grade_cat  total_pymnt  total_rec_prncp  installment  region  \n",
       "0          2            1                1            0       4  \n",
       "1          3            0                0            0       0  \n",
       "2          3            0                0            0       3  \n",
       "3          3            2                2            1       1  \n",
       "4          2            0                0            0       1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('C:/Users/sai kiran/Desktop/export_dataframe.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "868946"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.89014161  0.70229024 -0.5539965  ...  3.59711753  0.33101202\n",
      "  -0.69837922]\n",
      " [-2.57951727 -0.47178081  1.07879067 ...  3.53516106  0.2324732\n",
      "   1.22597546]\n",
      " [-1.63698094 -0.48746871  0.71798891 ...  3.75933344  0.64401473\n",
      "  -0.40616948]\n",
      " ...\n",
      " [ 1.36910677 -1.8013107   1.70012963 ... -0.25367366 -0.84646413\n",
      "  -0.06718639]\n",
      " [ 1.49016829 -1.78105474  2.44270258 ...  0.28716615 -1.19942499\n",
      "   0.69229817]\n",
      " [-3.97930216  0.30563148  0.05818335 ... -1.17746463 -1.06714536\n",
      "  -0.98899714]] [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "(868946, 7) (868946, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression,Perceptron\n",
    "pca = PCA(n_components=7)\n",
    "y=data['loan_condition'].values\n",
    "data.drop('loan_condition',axis=1,inplace=True)\n",
    "X=data[:].values\n",
    "y=y.reshape(-1, 1)\n",
    "x = pca.fit_transform(X)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y)\n",
    "print(x,y)\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9221955744187225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6855855341638708, 0.512409907646167, 0.505793115226984, None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic=LogisticRegression()\n",
    "logistic.fit(x_train,y_train)\n",
    "pred=logistic.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925040393671428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7348971968947641, 0.6722771549502379, 0.6974165633722229, None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "pred=clf.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9183058134663985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6393368860358625, 0.5285819992924325, 0.5352918622668803, None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf= GaussianNB()\n",
    "clf.fit(x_train,y_train)\n",
    "pred=clf.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926904716968104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8685349979242201, 0.5348240467114894, 0.5462404256765552, None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "clf.fit(x_train,y_train)\n",
    "pred=clf.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "651709/651709 [==============================] - 27s 42us/step - loss: 0.2277 - acc: 0.9242\n",
      "Epoch 2/50\n",
      "651709/651709 [==============================] - 27s 41us/step - loss: 0.2209 - acc: 0.9265\n",
      "Epoch 3/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.2194 - acc: 0.9268\n",
      "Epoch 4/50\n",
      "651709/651709 [==============================] - 27s 42us/step - loss: 0.2175 - acc: 0.9277\n",
      "Epoch 5/50\n",
      "651709/651709 [==============================] - 28s 43us/step - loss: 0.2153 - acc: 0.9288\n",
      "Epoch 6/50\n",
      "651709/651709 [==============================] - 27s 41us/step - loss: 0.2133 - acc: 0.9294\n",
      "Epoch 7/50\n",
      "651709/651709 [==============================] - 28s 43us/step - loss: 0.2111 - acc: 0.9299 0s - loss: 0.2110 - acc: 0.929\n",
      "Epoch 8/50\n",
      "651709/651709 [==============================] - 27s 42us/step - loss: 0.2072 - acc: 0.9316\n",
      "Epoch 9/50\n",
      "651709/651709 [==============================] - 27s 42us/step - loss: 0.2027 - acc: 0.9345\n",
      "Epoch 10/50\n",
      "651709/651709 [==============================] - 29s 44us/step - loss: 0.2011 - acc: 0.9352\n",
      "Epoch 11/50\n",
      "651709/651709 [==============================] - 27s 42us/step - loss: 0.1990 - acc: 0.9357\n",
      "Epoch 12/50\n",
      "651709/651709 [==============================] - 27s 42us/step - loss: 0.1959 - acc: 0.9365\n",
      "Epoch 13/50\n",
      "651709/651709 [==============================] - 27s 42us/step - loss: 0.1929 - acc: 0.9373 7s - l\n",
      "Epoch 14/50\n",
      "651709/651709 [==============================] - 28s 43us/step - loss: 0.1908 - acc: 0.9380 8s - loss: 0.1906 - acc:  - ETA: 8s - loss: 0.1905 - a\n",
      "Epoch 15/50\n",
      "651709/651709 [==============================] - 29s 44us/step - loss: 0.1896 - acc: 0.9388 0s - loss: 0\n",
      "Epoch 16/50\n",
      "651709/651709 [==============================] - 29s 44us/step - loss: 0.1887 - acc: 0.9395 0s - loss: 0.1887 - acc: 0.939\n",
      "Epoch 17/50\n",
      "651709/651709 [==============================] - 28s 43us/step - loss: 0.1883 - acc: 0.9399 5s\n",
      "Epoch 18/50\n",
      "651709/651709 [==============================] - 27s 41us/step - loss: 0.1878 - acc: 0.9401\n",
      "Epoch 19/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1875 - acc: 0.9403\n",
      "Epoch 20/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1871 - acc: 0.9405\n",
      "Epoch 21/50\n",
      "651709/651709 [==============================] - 26s 39us/step - loss: 0.1869 - acc: 0.9406\n",
      "Epoch 22/50\n",
      "651709/651709 [==============================] - 27s 41us/step - loss: 0.1866 - acc: 0.9408\n",
      "Epoch 23/50\n",
      "651709/651709 [==============================] - 25s 39us/step - loss: 0.1864 - acc: 0.9409\n",
      "Epoch 24/50\n",
      "651709/651709 [==============================] - 25s 38us/step - loss: 0.1862 - acc: 0.9407\n",
      "Epoch 25/50\n",
      "651709/651709 [==============================] - 27s 41us/step - loss: 0.1861 - acc: 0.9410\n",
      "Epoch 26/50\n",
      "651709/651709 [==============================] - 28s 43us/step - loss: 0.1860 - acc: 0.9408 0s - loss: 0.1860 - a\n",
      "Epoch 27/50\n",
      "651709/651709 [==============================] - 26s 41us/step - loss: 0.1859 - acc: 0.9410\n",
      "Epoch 28/50\n",
      "651709/651709 [==============================] - 39s 60us/step - loss: 0.1858 - acc: 0.9411 2 - ETA: 0s - loss: 0.1859 - ac\n",
      "Epoch 29/50\n",
      "651709/651709 [==============================] - 32s 49us/step - loss: 0.1857 - acc: 0.9411 0s - loss: 0.1858 - acc: 0\n",
      "Epoch 30/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1857 - acc: 0.9412 0s - loss: 0.1\n",
      "Epoch 31/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1855 - acc: 0.9413\n",
      "Epoch 32/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1855 - acc: 0.9414\n",
      "Epoch 33/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1855 - acc: 0.9414\n",
      "Epoch 34/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1853 - acc: 0.9414 10s\n",
      "Epoch 35/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1853 - acc: 0.9415\n",
      "Epoch 36/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1852 - acc: 0.9415 3s - l\n",
      "Epoch 37/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1851 - acc: 0.9415 \n",
      "Epoch 38/50\n",
      "651709/651709 [==============================] - 25s 38us/step - loss: 0.1851 - acc: 0.9415\n",
      "Epoch 39/50\n",
      "651709/651709 [==============================] - 25s 38us/step - loss: 0.1849 - acc: 0.9416\n",
      "Epoch 40/50\n",
      "651709/651709 [==============================] - 25s 39us/step - loss: 0.1849 - acc: 0.9416\n",
      "Epoch 41/50\n",
      "651709/651709 [==============================] - 25s 38us/step - loss: 0.1848 - acc: 0.9417\n",
      "Epoch 42/50\n",
      "651709/651709 [==============================] - 25s 39us/step - loss: 0.1848 - acc: 0.9417\n",
      "Epoch 43/50\n",
      "651709/651709 [==============================] - 25s 38us/step - loss: 0.1848 - acc: 0.9418\n",
      "Epoch 44/50\n",
      "651709/651709 [==============================] - 29s 44us/step - loss: 0.1848 - acc: 0.9417\n",
      "Epoch 45/50\n",
      "651709/651709 [==============================] - 25s 39us/step - loss: 0.1847 - acc: 0.9417 6s - loss: 0.1846 - ac - ETA: 4s - l - ETA: 3s - loss: \n",
      "Epoch 46/50\n",
      "651709/651709 [==============================] - 26s 41us/step - loss: 0.1846 - acc: 0.9418 0s - loss: 0.1845 - \n",
      "Epoch 47/50\n",
      "651709/651709 [==============================] - 26s 39us/step - loss: 0.1845 - acc: 0.9418 0s - loss: \n",
      "Epoch 48/50\n",
      "651709/651709 [==============================] - 26s 39us/step - loss: 0.1845 - acc: 0.9418\n",
      "Epoch 49/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1845 - acc: 0.9419 1s - loss: 0 - ETA: 0s - loss: 0.1846 -\n",
      "Epoch 50/50\n",
      "651709/651709 [==============================] - 26s 39us/step - loss: 0.1845 - acc: 0.9418\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_7_input to have shape (7,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-8ba90f199cc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_7_input to have shape (7,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=7, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train, epochs=50, batch_size=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217237/217237 [==============================] - 3s 15us/step\n",
      "[0.1888760722026692, 0.9404014969828326]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8845761632859901, 0.6425680053948992, 0.6990401491578825, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test,y_test)\n",
    "print(accuracy)\n",
    "pred=model.predict_classes(x_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.86311649 -1.94146222  0.9559941  ...  2.97837388  0.25000549\n",
      "  -0.90587634]\n",
      " [ 6.0197011  -0.91226898 -0.48355861 ... -0.47292508  0.14684092\n",
      "  -0.57750172]\n",
      " [ 7.1005899  -0.48488628 -0.53969513 ...  2.31815105  0.57393121\n",
      "  -0.49440892]\n",
      " ...\n",
      " [11.30140821  0.20611554 -1.80283877 ... -1.47801614 -0.83923322\n",
      "   0.19525852]\n",
      " [11.79770931 -0.04256594 -1.66522174 ...  0.56048299 -1.18360123\n",
      "   0.41963723]\n",
      " [ 8.34040461 -3.51717606  1.10033237 ... -2.06798375 -1.06412554\n",
      "  -0.08472932]] [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "(868946, 7) (868946, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=7, n_iter=7, random_state=42)\n",
    "x=svd.fit_transform(X)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y)\n",
    "print(x,y)\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9227755861110216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7091818768724476, 0.5347280550638414, 0.5456339587162701, None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic=LogisticRegression()\n",
    "logistic.fit(x_train,y_train)\n",
    "pred=logistic.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298323950339952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7566234130989931, 0.6879353158217046, 0.7155770004667814, None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "pred=clf.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9225408194736624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6976706260080744, 0.5209283049058251, 0.5218527560732119, None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf= GaussianNB()\n",
    "clf.fit(x_train,y_train)\n",
    "pred=clf.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9307300321768391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.918727387944231, 0.5554496156914325, 0.5814739538993264, None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "clf.fit(x_train,y_train)\n",
    "pred=clf.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.2075 - acc: 0.9302\n",
      "Epoch 2/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.1855 - acc: 0.9395\n",
      "Epoch 3/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.1781 - acc: 0.9433\n",
      "Epoch 4/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.1759 - acc: 0.9444\n",
      "Epoch 5/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.1749 - acc: 0.9451\n",
      "Epoch 6/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.1743 - acc: 0.9454\n",
      "Epoch 7/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.1736 - acc: 0.9459\n",
      "Epoch 8/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.1730 - acc: 0.9461\n",
      "Epoch 9/50\n",
      "651709/651709 [==============================] - 20s 30us/step - loss: 0.1724 - acc: 0.9463\n",
      "Epoch 10/50\n",
      "651709/651709 [==============================] - 21s 33us/step - loss: 0.1717 - acc: 0.9466\n",
      "Epoch 11/50\n",
      "651709/651709 [==============================] - 20s 30us/step - loss: 0.1712 - acc: 0.9468\n",
      "Epoch 12/50\n",
      "651709/651709 [==============================] - 22s 34us/step - loss: 0.1708 - acc: 0.9472\n",
      "Epoch 13/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1704 - acc: 0.9473\n",
      "Epoch 14/50\n",
      "651709/651709 [==============================] - 26s 39us/step - loss: 0.1702 - acc: 0.9473\n",
      "Epoch 15/50\n",
      "651709/651709 [==============================] - 19s 30us/step - loss: 0.1701 - acc: 0.9475\n",
      "Epoch 16/50\n",
      "651709/651709 [==============================] - 20s 31us/step - loss: 0.1699 - acc: 0.9474\n",
      "Epoch 17/50\n",
      "651709/651709 [==============================] - 23s 35us/step - loss: 0.1698 - acc: 0.9475\n",
      "Epoch 18/50\n",
      "651709/651709 [==============================] - 22s 34us/step - loss: 0.1697 - acc: 0.9476 0s - loss: 0.1698 - \n",
      "Epoch 19/50\n",
      "651709/651709 [==============================] - 23s 36us/step - loss: 0.1696 - acc: 0.9476\n",
      "Epoch 20/50\n",
      "651709/651709 [==============================] - 24s 37us/step - loss: 0.1696 - acc: 0.9476\n",
      "Epoch 21/50\n",
      "651709/651709 [==============================] - 28s 43us/step - loss: 0.1696 - acc: 0.9477\n",
      "Epoch 22/50\n",
      "651709/651709 [==============================] - 27s 42us/step - loss: 0.1694 - acc: 0.9477 0s - loss: 0.1694 -\n",
      "Epoch 23/50\n",
      "651709/651709 [==============================] - 26s 41us/step - loss: 0.1694 - acc: 0.9476\n",
      "Epoch 24/50\n",
      "651709/651709 [==============================] - 29s 45us/step - loss: 0.1693 - acc: 0.9477\n",
      "Epoch 25/50\n",
      "651709/651709 [==============================] - 26s 40us/step - loss: 0.1693 - acc: 0.9477\n",
      "Epoch 26/50\n",
      "651709/651709 [==============================] - 22s 33us/step - loss: 0.1692 - acc: 0.9478\n",
      "Epoch 27/50\n",
      "651709/651709 [==============================] - 21s 33us/step - loss: 0.1692 - acc: 0.9477\n",
      "Epoch 28/50\n",
      "651709/651709 [==============================] - 22s 34us/step - loss: 0.1692 - acc: 0.9477 1s - \n",
      "Epoch 29/50\n",
      "651709/651709 [==============================] - 22s 34us/step - loss: 0.1690 - acc: 0.9478 0s - loss: 0.169\n",
      "Epoch 30/50\n",
      "651709/651709 [==============================] - 23s 35us/step - loss: 0.1690 - acc: 0.9478 1s \n",
      "Epoch 31/50\n",
      "651709/651709 [==============================] - 23s 35us/step - loss: 0.1690 - acc: 0.9477\n",
      "Epoch 32/50\n",
      "651709/651709 [==============================] - 23s 35us/step - loss: 0.1690 - acc: 0.9478\n",
      "Epoch 33/50\n",
      "651709/651709 [==============================] - 23s 35us/step - loss: 0.1690 - acc: 0.9478\n",
      "Epoch 34/50\n",
      "651709/651709 [==============================] - 22s 34us/step - loss: 0.1689 - acc: 0.9479\n",
      "Epoch 35/50\n",
      "651709/651709 [==============================] - 22s 34us/step - loss: 0.1688 - acc: 0.9478\n",
      "Epoch 36/50\n",
      "651709/651709 [==============================] - 23s 35us/step - loss: 0.1689 - acc: 0.9477 1s - loss: 0.1690 -  - ETA: 0s - loss: 0.1\n",
      "Epoch 37/50\n",
      "651709/651709 [==============================] - 22s 34us/step - loss: 0.1689 - acc: 0.9478 2s - loss: 0.1684 - acc: 0.9 - ETA: 2s - loss: 0.1683\n",
      "Epoch 38/50\n",
      "651709/651709 [==============================] - 24s 37us/step - loss: 0.1689 - acc: 0.9477 2s - loss: 0.1689 - a\n",
      "Epoch 39/50\n",
      "651709/651709 [==============================] - 23s 35us/step - loss: 0.1688 - acc: 0.9478\n",
      "Epoch 40/50\n",
      "651709/651709 [==============================] - 19s 30us/step - loss: 0.1688 - acc: 0.9479\n",
      "Epoch 41/50\n",
      "651709/651709 [==============================] - 20s 30us/step - loss: 0.1687 - acc: 0.9478\n",
      "Epoch 42/50\n",
      "651709/651709 [==============================] - 19s 30us/step - loss: 0.1687 - acc: 0.9478\n",
      "Epoch 43/50\n",
      "651709/651709 [==============================] - 20s 31us/step - loss: 0.1686 - acc: 0.9478\n",
      "Epoch 44/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1686 - acc: 0.9479\n",
      "Epoch 45/50\n",
      "651709/651709 [==============================] - 19s 28us/step - loss: 0.1686 - acc: 0.9478\n",
      "Epoch 46/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1686 - acc: 0.9478\n",
      "Epoch 47/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1686 - acc: 0.9478\n",
      "Epoch 48/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1686 - acc: 0.9478\n",
      "Epoch 49/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1685 - acc: 0.9478\n",
      "Epoch 50/50\n",
      "651709/651709 [==============================] - 19s 30us/step - loss: 0.1685 - acc: 0.9478 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc04de50f0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=7, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train, epochs=50, batch_size=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217237/217237 [==============================] - 4s 17us/step\n",
      "[0.1713296390095751, 0.9470302020374062]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9173678724484162, 0.677194749478934, 0.7410770497389415, None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test,y_test)\n",
    "print(accuracy)\n",
    "pred=model.predict_classes(x_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04597204 0.00640539 0.02430839 ... 0.06902412 0.0227074  0.        ]\n",
      " [0.04627415 0.01900537 0.0006218  ... 0.00039886 0.01206738 0.        ]\n",
      " [0.04611406 0.03162947 0.00069075 ... 0.05182194 0.02219937 0.        ]\n",
      " ...\n",
      " [0.09073712 0.06326519 0.         ... 0.         0.00984374 0.02006341]\n",
      " [0.08947158 0.06337308 0.         ... 0.03473491 0.0003652  0.02122615]\n",
      " [0.08884292 0.00058509 0.03524414 ... 0.         0.0168514  0.03508642]] [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "(868946, 7) (868946, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "clf = NMF(n_components=7)\n",
    "x=clf.fit_transform(X)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y)\n",
    "print(x,y)\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9239678323674144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7083689656759058, 0.5257480888558145, 0.5306615541725348, None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic=LogisticRegression()\n",
    "logistic.fit(x_train,y_train)\n",
    "pred=logistic.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9331927802354111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7667749802320383, 0.7055790349239806, 0.7311995025606242, None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "pred=clf.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9209204693491441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6500276758118826, 0.52677378671329, 0.5325731597717687, None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf= GaussianNB()\n",
    "clf.fit(x_train,y_train)\n",
    "pred=clf.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9393473487481414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9214288297875766, 0.611209080051438, 0.6638110245569404, None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "clf.fit(x_train,y_train)\n",
    "pred=clf.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "651709/651709 [==============================] - 20s 31us/step - loss: 0.2336 - acc: 0.9234\n",
      "Epoch 2/50\n",
      "651709/651709 [==============================] - 19s 30us/step - loss: 0.2039 - acc: 0.9289\n",
      "Epoch 3/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1910 - acc: 0.9374\n",
      "Epoch 4/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1867 - acc: 0.9404\n",
      "Epoch 5/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.1852 - acc: 0.9414\n",
      "Epoch 6/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.1843 - acc: 0.9416\n",
      "Epoch 7/50\n",
      "651709/651709 [==============================] - 17s 27us/step - loss: 0.1839 - acc: 0.9417\n",
      "Epoch 8/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.1833 - acc: 0.9421\n",
      "Epoch 9/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.1827 - acc: 0.9424\n",
      "Epoch 10/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.1820 - acc: 0.9428\n",
      "Epoch 11/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1818 - acc: 0.9430\n",
      "Epoch 12/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.1813 - acc: 0.9434\n",
      "Epoch 13/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.1811 - acc: 0.9433\n",
      "Epoch 14/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.1811 - acc: 0.9435\n",
      "Epoch 15/50\n",
      "651709/651709 [==============================] - 17s 25us/step - loss: 0.1810 - acc: 0.9435\n",
      "Epoch 16/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.1809 - acc: 0.9434\n",
      "Epoch 17/50\n",
      "651709/651709 [==============================] - 16s 25us/step - loss: 0.1808 - acc: 0.9436\n",
      "Epoch 18/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1807 - acc: 0.9436\n",
      "Epoch 19/50\n",
      "651709/651709 [==============================] - 16s 25us/step - loss: 0.1804 - acc: 0.9437\n",
      "Epoch 20/50\n",
      "651709/651709 [==============================] - 31s 48us/step - loss: 0.1805 - acc: 0.9437 0s - los\n",
      "Epoch 21/50\n",
      "651709/651709 [==============================] - 23s 35us/step - loss: 0.1802 - acc: 0.9437\n",
      "Epoch 22/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.1799 - acc: 0.9440\n",
      "Epoch 23/50\n",
      "651709/651709 [==============================] - 20s 31us/step - loss: 0.1797 - acc: 0.9441\n",
      "Epoch 24/50\n",
      "651709/651709 [==============================] - 20s 31us/step - loss: 0.1795 - acc: 0.9441\n",
      "Epoch 25/50\n",
      "651709/651709 [==============================] - 20s 31us/step - loss: 0.1794 - acc: 0.9444\n",
      "Epoch 26/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1794 - acc: 0.9444\n",
      "Epoch 27/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1793 - acc: 0.9444\n",
      "Epoch 28/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1792 - acc: 0.9444\n",
      "Epoch 29/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.1787 - acc: 0.9446\n",
      "Epoch 30/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.1782 - acc: 0.9449\n",
      "Epoch 31/50\n",
      "651709/651709 [==============================] - 17s 27us/step - loss: 0.1780 - acc: 0.9451\n",
      "Epoch 32/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1779 - acc: 0.9452\n",
      "Epoch 33/50\n",
      "651709/651709 [==============================] - 17s 27us/step - loss: 0.1778 - acc: 0.9451 0s - loss: 0.1777 - acc: 0\n",
      "Epoch 34/50\n",
      "651709/651709 [==============================] - 16s 25us/step - loss: 0.1776 - acc: 0.9454\n",
      "Epoch 35/50\n",
      "651709/651709 [==============================] - 16s 25us/step - loss: 0.1775 - acc: 0.9454\n",
      "Epoch 36/50\n",
      "651709/651709 [==============================] - 17s 27us/step - loss: 0.1773 - acc: 0.9454\n",
      "Epoch 37/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.1772 - acc: 0.9455\n",
      "Epoch 38/50\n",
      "651709/651709 [==============================] - 17s 27us/step - loss: 0.1771 - acc: 0.9454\n",
      "Epoch 39/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.1770 - acc: 0.9455\n",
      "Epoch 40/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.1769 - acc: 0.9454\n",
      "Epoch 41/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.1769 - acc: 0.9455\n",
      "Epoch 42/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.1768 - acc: 0.9456\n",
      "Epoch 43/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.1769 - acc: 0.9455\n",
      "Epoch 44/50\n",
      "651709/651709 [==============================] - 17s 27us/step - loss: 0.1767 - acc: 0.9455\n",
      "Epoch 45/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.1766 - acc: 0.9456\n",
      "Epoch 46/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.1767 - acc: 0.9456\n",
      "Epoch 47/50\n",
      "651709/651709 [==============================] - 17s 27us/step - loss: 0.1766 - acc: 0.9456\n",
      "Epoch 48/50\n",
      "651709/651709 [==============================] - 17s 27us/step - loss: 0.1766 - acc: 0.9456\n",
      "Epoch 49/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.1767 - acc: 0.9456\n",
      "Epoch 50/50\n",
      "651709/651709 [==============================] - 17s 27us/step - loss: 0.1765 - acc: 0.9455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc0a85a0b8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=7, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train, epochs=50, batch_size=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217237/217237 [==============================] - 3s 15us/step\n",
      "[0.1741297648134226, 0.9460174832098566]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8912287048799531, 0.6773880273366365, 0.737412144852754, None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test,y_test)\n",
    "print(accuracy)\n",
    "pred=model.predict_classes(x_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.21754752]\n",
      " [ 0.79043634]\n",
      " [ 0.06645559]\n",
      " ...\n",
      " [ 0.5435069 ]\n",
      " [ 0.00914426]\n",
      " [ 0.99547721]] [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "(651709, 1) (651709, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from timeit import default_timer\n",
    "lda = LDA()\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y)\n",
    "x_train = lda.fit_transform(x_train, y_train)\n",
    "x_test = lda.transform(x_test)\n",
    "print(x_train,y_train)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6350636000000001\n",
      "0.9243637133637456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7234937219254355, 0.5484254651861118, 0.5674061607697134, None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logistic=LogisticRegression()\n",
    "start = default_timer()\n",
    "logistic.fit(x_train,y_train)\n",
    "print(default_timer() - start)\n",
    "pred=logistic.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7886235\n",
      "0.9158246523382296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6849202057084666, 0.634869330895734, 0.6546881606679871, None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "start = default_timer()\n",
    "clf.fit(x_train,y_train)\n",
    "print(default_timer() - start)\n",
    "pred=clf.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07196719999999956\n",
      "0.9242532349461647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7214334574114927, 0.5790443752735743, 0.6084173125331338, None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf= GaussianNB()\n",
    "start = default_timer()\n",
    "clf.fit(x_train,y_train)\n",
    "print(default_timer() - start)\n",
    "pred=clf.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.524409399999996\n",
      "0.9253303995175776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7390532727152104, 0.5525546375958382, 0.5739538146115359, None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "start = default_timer()\n",
    "clf.fit(x_train,y_train)\n",
    "print(default_timer() - start)\n",
    "pred=clf.predict(x_test)\n",
    "print(accuracy_score(pred,y_test))\n",
    "confusion_matrix(pred,y_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.2198 - acc: 0.9232\n",
      "Epoch 2/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.2166 - acc: 0.9236\n",
      "Epoch 3/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.2166 - acc: 0.9238\n",
      "Epoch 4/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.2166 - acc: 0.9236\n",
      "Epoch 5/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.2166 - acc: 0.9236\n",
      "Epoch 6/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.2165 - acc: 0.9237\n",
      "Epoch 7/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.2165 - acc: 0.9236\n",
      "Epoch 8/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.2165 - acc: 0.9237\n",
      "Epoch 9/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.2165 - acc: 0.9236\n",
      "Epoch 10/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.2164 - acc: 0.9235 0s - loss: 0.2\n",
      "Epoch 11/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.2165 - acc: 0.9236\n",
      "Epoch 12/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.2165 - acc: 0.9237\n",
      "Epoch 13/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.2165 - acc: 0.9237\n",
      "Epoch 14/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.2164 - acc: 0.9236 0s - loss: 0.2165 - acc: 0.\n",
      "Epoch 15/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.2164 - acc: 0.9236\n",
      "Epoch 16/50\n",
      "651709/651709 [==============================] - 21s 32us/step - loss: 0.2164 - acc: 0.9237\n",
      "Epoch 17/50\n",
      "651709/651709 [==============================] - 23s 35us/step - loss: 0.2164 - acc: 0.9236\n",
      "Epoch 18/50\n",
      "651709/651709 [==============================] - 21s 32us/step - loss: 0.2164 - acc: 0.9237\n",
      "Epoch 19/50\n",
      "651709/651709 [==============================] - 21s 32us/step - loss: 0.2164 - acc: 0.9237\n",
      "Epoch 20/50\n",
      "651709/651709 [==============================] - 21s 32us/step - loss: 0.2164 - acc: 0.9237\n",
      "Epoch 21/50\n",
      "651709/651709 [==============================] - 21s 33us/step - loss: 0.2164 - acc: 0.9236\n",
      "Epoch 22/50\n",
      "651709/651709 [==============================] - 22s 33us/step - loss: 0.2164 - acc: 0.9238 1s - los\n",
      "Epoch 23/50\n",
      "651709/651709 [==============================] - 22s 33us/step - loss: 0.2164 - acc: 0.9237\n",
      "Epoch 24/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.2164 - acc: 0.9238\n",
      "Epoch 25/50\n",
      "651709/651709 [==============================] - 18s 28us/step - loss: 0.2164 - acc: 0.9236\n",
      "Epoch 26/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.2163 - acc: 0.9237\n",
      "Epoch 27/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.2163 - acc: 0.9237\n",
      "Epoch 28/50\n",
      "651709/651709 [==============================] - 18s 27us/step - loss: 0.2164 - acc: 0.9238\n",
      "Epoch 29/50\n",
      "651709/651709 [==============================] - 17s 27us/step - loss: 0.2164 - acc: 0.9236\n",
      "Epoch 30/50\n",
      "651709/651709 [==============================] - 17s 27us/step - loss: 0.2164 - acc: 0.9238\n",
      "Epoch 31/50\n",
      "651709/651709 [==============================] - 22s 33us/step - loss: 0.2163 - acc: 0.9238\n",
      "Epoch 32/50\n",
      "651709/651709 [==============================] - 19s 30us/step - loss: 0.2163 - acc: 0.9238\n",
      "Epoch 33/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.2164 - acc: 0.9238\n",
      "Epoch 34/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.2164 - acc: 0.9237\n",
      "Epoch 35/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.2163 - acc: 0.9237\n",
      "Epoch 36/50\n",
      "651709/651709 [==============================] - 17s 27us/step - loss: 0.2164 - acc: 0.9237\n",
      "Epoch 37/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.2164 - acc: 0.9238\n",
      "Epoch 38/50\n",
      "651709/651709 [==============================] - 17s 26us/step - loss: 0.2163 - acc: 0.9237\n",
      "Epoch 39/50\n",
      "651709/651709 [==============================] - 20s 31us/step - loss: 0.2164 - acc: 0.9236\n",
      "Epoch 40/50\n",
      "651709/651709 [==============================] - 20s 31us/step - loss: 0.2164 - acc: 0.9237\n",
      "Epoch 41/50\n",
      "651709/651709 [==============================] - 21s 32us/step - loss: 0.2163 - acc: 0.9237\n",
      "Epoch 42/50\n",
      "651709/651709 [==============================] - 20s 31us/step - loss: 0.2163 - acc: 0.9236\n",
      "Epoch 43/50\n",
      "651709/651709 [==============================] - 21s 32us/step - loss: 0.2163 - acc: 0.9237\n",
      "Epoch 44/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.2163 - acc: 0.9237\n",
      "Epoch 45/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.2163 - acc: 0.9238\n",
      "Epoch 46/50\n",
      "651709/651709 [==============================] - 20s 30us/step - loss: 0.2163 - acc: 0.9239\n",
      "Epoch 47/50\n",
      "651709/651709 [==============================] - 19s 30us/step - loss: 0.2163 - acc: 0.9238\n",
      "Epoch 48/50\n",
      "651709/651709 [==============================] - 20s 30us/step - loss: 0.2163 - acc: 0.9236\n",
      "Epoch 49/50\n",
      "651709/651709 [==============================] - 19s 30us/step - loss: 0.2163 - acc: 0.9238\n",
      "Epoch 50/50\n",
      "651709/651709 [==============================] - 19s 29us/step - loss: 0.2163 - acc: 0.9238\n",
      "942.6035241\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=1, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "start = default_timer()\n",
    "model.fit(x_train,y_train, epochs=50, batch_size=42)\n",
    "print(default_timer() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217237/217237 [==============================] - 3s 16us/step\n",
      "[0.21568455894615707, 0.9245524473273872]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.724928553702827, 0.5647823282053097, 0.590571199859302, None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test,y_test)\n",
    "print(accuracy)\n",
    "pred=model.predict_classes(x_test)\n",
    "precision_recall_fscore_support(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
