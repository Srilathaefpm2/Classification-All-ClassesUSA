{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>emp_length_int</th>\n",
       "      <th>home_ownership_cat</th>\n",
       "      <th>income_cat</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>term_cat</th>\n",
       "      <th>purpose_cat</th>\n",
       "      <th>interest_payment_cat</th>\n",
       "      <th>loan_condition</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>grade_cat</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>installment</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  emp_length_int  home_ownership_cat  income_cat  loan_amount  \\\n",
       "0     4               2                   1           1            0   \n",
       "1     4               0                   1           1            0   \n",
       "2     4               2                   1           1            0   \n",
       "3     4               2                   1           1            1   \n",
       "4     4               0                   1           1            0   \n",
       "\n",
       "   term_cat  purpose_cat  interest_payment_cat  loan_condition  interest_rate  \\\n",
       "0         1            1                     1               1              2   \n",
       "1         2            2                     2               0              3   \n",
       "2         1            3                     2               1              3   \n",
       "3         1            4                     2               1              2   \n",
       "4         2            4                     1               1              2   \n",
       "\n",
       "   grade_cat  total_pymnt  total_rec_prncp  installment  region  \n",
       "0          2            1                1            0       4  \n",
       "1          3            0                0            0       0  \n",
       "2          3            0                0            0       3  \n",
       "3          3            2                2            1       1  \n",
       "4          2            0                0            0       1  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('C:/Users/sai kiran/Desktop/export_dataframe.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868946, 14) (868946, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "sm = SMOTE(random_state = 2)\n",
    "y=data['loan_condition'].values\n",
    "data.drop('loan_condition',axis=1,inplace=True)\n",
    "X=data[:].values\n",
    "y=y.reshape(-1, 1)\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(882743, 14) (882743,)\n"
     ]
    }
   ],
   "source": [
    "over = RandomOverSampler(sampling_strategy=0.1)\n",
    "# fit and apply the transform\n",
    "X, y = over.fit_resample(X, y)\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.8627957  -1.95920623  0.92471744 ...  2.975936    0.23577724\n",
      "  -0.91448645]\n",
      " [ 6.0235595  -0.90612212 -0.49872864 ... -0.48938321  0.13571376\n",
      "  -0.58894622]\n",
      " [ 7.10445197 -0.47774717 -0.54680492 ...  2.30670491  0.55910759\n",
      "  -0.5106069 ]\n",
      " ...\n",
      " [ 6.4957609  -1.41414424 -0.27993981 ...  0.93623917 -0.20101721\n",
      "  -0.9385008 ]\n",
      " [ 7.47582235 -2.76846575  2.0371309  ...  1.29800424 -0.63945565\n",
      "  -0.52555171]\n",
      " [11.26374589  0.18308336 -0.68245682 ... -2.04974761  0.10663226\n",
      "   2.05694783]] [1 0 1 ... 0 0 0]\n",
      "(882743, 7) (882743,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "kf5 = KFold(n_splits=5)\n",
    "kf2 = KFold(n_splits=2)\n",
    "kf3 = KFold(n_splits=3)\n",
    "kf10 =KFold(n_splits=10)\n",
    "from sklearn.linear_model import LogisticRegression,Perceptron\n",
    "svd = TruncatedSVD(n_components=7, n_iter=7, random_state=42)\n",
    "x=svd.fit_transform(X)\n",
    "print(x,y)\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf10.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 88275  88276  88277 ... 882740 882741 882742] TEST: [    0     1     2 ... 88272 88273 88274]\n",
      "(794468, 7) (88275, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [ 88275  88276  88277 ... 176547 176548 176549]\n",
      "(794468, 7) (88275, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [176550 176551 176552 ... 264822 264823 264824]\n",
      "(794468, 7) (88275, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [264825 264826 264827 ... 353096 353097 353098]\n",
      "(794469, 7) (88274, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [353099 353100 353101 ... 441370 441371 441372]\n",
      "(794469, 7) (88274, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [441373 441374 441375 ... 529644 529645 529646]\n",
      "(794469, 7) (88274, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [529647 529648 529649 ... 617918 617919 617920]\n",
      "(794469, 7) (88274, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [617921 617922 617923 ... 706192 706193 706194]\n",
      "(794469, 7) (88274, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [706195 706196 706197 ... 794466 794467 794468]\n",
      "(794469, 7) (88274, 7)\n",
      "TRAIN: [     0      1      2 ... 794466 794467 794468] TEST: [794469 794470 794471 ... 882740 882741 882742]\n",
      "(794469, 7) (88274, 7)\n",
      "0.8869696839184977\n",
      "0.7483679128053466\n",
      "0.527322994708485\n",
      "0.5084701968565243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "accuracy=0\n",
    "precision=0\n",
    "recall=0\n",
    "f_score=0\n",
    "for train_index, test_index in kf10.split(x,y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    logistic=LogisticRegression()\n",
    "    logistic.fit(X_train,y_train)\n",
    "    pred=logistic.predict(X_test)\n",
    "    acc=accuracy_score(pred,y_test)\n",
    "    accuracy=accuracy+acc\n",
    "    confusion_matrix(pred,y_test)\n",
    "    a,b,c,d=precision_recall_fscore_support(y_test, pred, average='macro')\n",
    "    precision=precision+a\n",
    "    recall=recall+b\n",
    "    f_score=f_score+c\n",
    "print(accuracy/10)\n",
    "print(precision/10)\n",
    "print(recall/10)\n",
    "print(f_score/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [441372 441373 441374 ... 882740 882741 882742] TEST: [     0      1      2 ... 441369 441370 441371]\n",
      "(441371, 7) (441372, 7)\n",
      "acc:  0.4924258901788061\n",
      "TRAIN: [     0      1      2 ... 441369 441370 441371] TEST: [441372 441373 441374 ... 882740 882741 882742]\n",
      "(441372, 7) (441371, 7)\n",
      "acc:  0.7960106123873113\n",
      "0.6442182512830588\n",
      "0.5432085817712156\n",
      "0.6013632805545897\n",
      "0.48052840039625017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "accuracy=0\n",
    "precision=0\n",
    "recall=0\n",
    "f_score=0\n",
    "for train_index, test_index in kf2.split(x,y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    logistic=LogisticRegression()\n",
    "    logistic.fit(X_train,y_train)\n",
    "    pred=logistic.predict(X_test)\n",
    "    acc=accuracy_score(pred,y_test)\n",
    "    print('acc: ',acc)\n",
    "    accuracy=accuracy+acc\n",
    "    confusion_matrix(pred,y_test)\n",
    "    a,b,c,d=precision_recall_fscore_support(y_test, pred, average='macro')\n",
    "    precision=precision+a\n",
    "    recall=recall+b\n",
    "    f_score=f_score+c\n",
    "print(accuracy/2)\n",
    "print(precision/2)\n",
    "print(recall/2)\n",
    "print(f_score/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [294248 294249 294250 ... 882740 882741 882742] TEST: [     0      1      2 ... 294245 294246 294247]\n",
      "(588495, 7) (294248, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [294248 294249 294250 ... 588493 588494 588495]\n",
      "(588495, 7) (294248, 7)\n",
      "TRAIN: [     0      1      2 ... 588493 588494 588495] TEST: [588496 588497 588498 ... 882740 882741 882742]\n",
      "(588496, 7) (294247, 7)\n",
      "0.8031670782463357\n",
      "0.6677830755649521\n",
      "0.573726899543784\n",
      "0.5129066996640083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "accuracy=0\n",
    "precision=0\n",
    "recall=0\n",
    "f_score=0\n",
    "for train_index, test_index in kf3.split(x,y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    logistic=LogisticRegression()\n",
    "    logistic.fit(X_train,y_train)\n",
    "    pred=logistic.predict(X_test)\n",
    "    acc=accuracy_score(pred,y_test)\n",
    "    accuracy=accuracy+acc\n",
    "    confusion_matrix(pred,y_test)\n",
    "    a,b,c,d=precision_recall_fscore_support(y_test, pred, average='macro')\n",
    "    precision=precision+a\n",
    "    recall=recall+b\n",
    "    f_score=f_score+c\n",
    "print(accuracy/3)\n",
    "print(precision/3)\n",
    "print(recall/3)\n",
    "print(f_score/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [176549 176550 176551 ... 882740 882741 882742] TEST: [     0      1      2 ... 176546 176547 176548]\n",
      "(706194, 7) (176549, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [176549 176550 176551 ... 353095 353096 353097]\n",
      "(706194, 7) (176549, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [353098 353099 353100 ... 529644 529645 529646]\n",
      "(706194, 7) (176549, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [529647 529648 529649 ... 706192 706193 706194]\n",
      "(706195, 7) (176548, 7)\n",
      "TRAIN: [     0      1      2 ... 706192 706193 706194] TEST: [706195 706196 706197 ... 882740 882741 882742]\n",
      "(706195, 7) (176548, 7)\n",
      "0.888162316786033\n",
      "0.7352356686607567\n",
      "0.5411119387388078\n",
      "0.5298172426202206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "accuracy=0\n",
    "precision=0\n",
    "recall=0\n",
    "f_score=0\n",
    "for train_index, test_index in kf5.split(x,y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    logistic=LogisticRegression()\n",
    "    logistic.fit(X_train,y_train)\n",
    "    pred=logistic.predict(X_test)\n",
    "    acc=accuracy_score(pred,y_test)\n",
    "    accuracy=accuracy+acc\n",
    "    confusion_matrix(pred,y_test)\n",
    "    a,b,c,d=precision_recall_fscore_support(y_test, pred, average='macro')\n",
    "    precision=precision+a\n",
    "    recall=recall+b\n",
    "    f_score=f_score+c\n",
    "print(accuracy/5)\n",
    "print(precision/5)\n",
    "print(recall/5)\n",
    "print(f_score/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 27220  27225  27239 ... 882740 882741 882742] TEST: [    0     1     2 ... 46976 46977 46978]\n",
      "(838605, 7) (44138, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [27220 27225 27239 ... 92584 92585 92586]\n",
      "(838605, 7) (44138, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [ 57143  57175  57188 ... 139013 139014 139015]\n",
      "(838605, 7) (44138, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [ 90359  90367  90369 ... 186205 186206 186207]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [120828 120838 120839 ... 233539 233540 233541]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [148079 148080 148083 ... 276765 276767 276768]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [175031 175052 175062 ... 320655 320656 320657]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [201913 201917 201919 ... 365079 365080 365081]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [226516 226517 226521 ... 409939 409940 409942]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [277926 277949 277975 ... 454954 454955 454956]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [324337 324349 324354 ... 496310 496311 496312]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [365562 365567 365597 ... 536702 536703 536704]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [404478 404488 404500 ... 577165 577166 577167]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [440861 440876 440888 ... 621432 621497 621506]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [617862 617863 617864 ... 754465 754472 754474]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [658769 658770 658771 ... 833288 833291 833302]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [700153 700154 700155 ... 870701 870702 870703]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [741854 741855 741856 ... 874714 874715 874716]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [783775 783776 783777 ... 878727 878728 878729]\n",
      "(838606, 7) (44137, 7)\n",
      "TRAIN: [     0      1      2 ... 878727 878728 878729] TEST: [826147 826148 826149 ... 882740 882741 882742]\n",
      "(838606, 7) (44137, 7)\n",
      "0.8869653276441227\n",
      "0.8277312291275563\n",
      "0.5404299957716392\n",
      "0.5276677247645603\n"
     ]
    }
   ],
   "source": [
    "kf20 = StratifiedKFold(n_splits=20)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "accuracy=0\n",
    "precision=0\n",
    "recall=0\n",
    "f_score=0\n",
    "for train_index, test_index in kf20.split(x,y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    logistic=LogisticRegression()\n",
    "    logistic.fit(X_train,y_train)\n",
    "    pred=logistic.predict(X_test)\n",
    "    acc=accuracy_score(pred,y_test)\n",
    "    accuracy=accuracy+acc\n",
    "    confusion_matrix(pred,y_test)\n",
    "    a,b,c,d=precision_recall_fscore_support(y_test, pred, average='macro')\n",
    "    precision=precision+a\n",
    "    recall=recall+b\n",
    "    f_score=f_score+c\n",
    "print(accuracy/20)\n",
    "print(precision/20)\n",
    "print(recall/20)\n",
    "print(f_score/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 10401  10402  10405 ... 882740 882741 882742] TEST: [    0     1     2 ... 18938 18939 18940]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [10401 10402 10405 ... 37347 37348 37350]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [21280 21285 21286 ... 56054 56055 56057]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [33935 33941 33955 ... 74228 74229 74230]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [43185 43189 43202 ... 92584 92585 92586]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [ 57133  57143  57175 ... 111032 111034 111035]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [ 70459  70470  70513 ... 129636 129637 129638]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [ 83786  83787  83793 ... 148531 148532 148535]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [ 96242  96252  96255 ... 167359 167360 167361]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [108711 108738 108739 ... 186205 186206 186207]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [120822 120828 120838 ... 205145 205146 205147]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [132131 132134 132135 ... 224391 224392 224393]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [142904 142906 142912 ... 242129 242131 242132]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [153325 153333 153334 ... 259462 259465 259467]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [164471 164472 164473 ... 276765 276767 276768]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [175031 175052 175062 ... 294282 294283 294284]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [186031 186033 186036 ... 311868 311869 311870]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [196629 196632 196647 ... 329514 329515 329516]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [206984 206995 206996 ... 347175 347176 347177]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [216083 216089 216098 ... 365079 365080 365081]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [226517 226521 226522 ... 382924 382925 382926]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [245697 245698 245699 ... 400870 400871 400873]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [266994 266997 267008 ... 418901 418903 418904]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [287316 287330 287344 ... 436953 436954 436955]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [306220 306237 306243 ... 454954 454955 454956]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [324354 324362 324366 ... 472225 472226 472227]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [342187 342193 342206 ... 488279 488280 488281]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [357518 357531 357543 ... 504373 504374 504375]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [373590 373596 373599 ... 520573 520574 520575]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [389494 389500 389503 ... 536702 536703 536704]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [404509 404525 404529 ... 552855 552856 552857]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [418909 418915 418928 ... 569080 569081 569082]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [433327 433331 433334 ... 585262 585263 585264]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [448009 448027 448028 ... 601591 601592 601593]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [462517 462529 462536 ... 621645 621655 621773]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [617862 617863 617864 ... 689515 689534 689768]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [634236 634237 634238 ... 734441 734465 734470]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [650569 650570 650571 ... 771881 771908 771956]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [667011 667012 667013 ... 803768 803802 803803]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [683577 683578 683579 ... 833304 833316 833319]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [700155 700156 700157 ... 859495 859507 859508]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [716786 716787 716788 ... 869901 869902 869903]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [733434 733435 733436 ... 871506 871507 871508]\n",
      "(865088, 7) (17655, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [750184 750185 750186 ... 873110 873111 873112]\n",
      "(865089, 7) (17654, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [766943 766944 766945 ... 874715 874716 874717]\n",
      "(865089, 7) (17654, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [783778 783779 783780 ... 876320 876321 876322]\n",
      "(865089, 7) (17654, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [800718 800720 800721 ... 877925 877926 877927]\n",
      "(865089, 7) (17654, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [817603 817604 817606 ... 879530 879531 879532]\n",
      "(865089, 7) (17654, 7)\n",
      "TRAIN: [     0      1      2 ... 882740 882741 882742] TEST: [834661 834662 834663 ... 881135 881136 881137]\n",
      "(865089, 7) (17654, 7)\n",
      "TRAIN: [     0      1      2 ... 881135 881136 881137] TEST: [851693 851694 851695 ... 882740 882741 882742]\n",
      "(865089, 7) (17654, 7)\n",
      "0.9045340392337213\n",
      "0.8280606343322638\n",
      "0.5435201853234048\n",
      "0.5367348959388242\n"
     ]
    }
   ],
   "source": [
    "kf50 = StratifiedKFold(n_splits=50)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "accuracy=0\n",
    "precision=0\n",
    "recall=0\n",
    "f_score=0\n",
    "for train_index, test_index in kf50.split(x,y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    logistic=LogisticRegression()\n",
    "    logistic.fit(X_train,y_train)\n",
    "    pred=logistic.predict(X_test)\n",
    "    acc=accuracy_score(pred,y_test)\n",
    "    accuracy=accuracy+acc\n",
    "    confusion_matrix(pred,y_test)\n",
    "    a,b,c,d=precision_recall_fscore_support(y_test, pred, average='macro')\n",
    "    precision=precision+a\n",
    "    recall=recall+b\n",
    "    f_score=f_score+c\n",
    "print(accuracy/50)\n",
    "print(precision/50)\n",
    "print(recall/50)\n",
    "print(f_score/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
